{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T22:01:11.023066Z",
     "iopub.status.busy": "2025-03-19T22:01:11.022754Z",
     "iopub.status.idle": "2025-03-19T22:01:11.027938Z",
     "shell.execute_reply": "2025-03-19T22:01:11.027014Z",
     "shell.execute_reply.started": "2025-03-19T22:01:11.023045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "Make sure to verify the file paths if you're running on a different platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T22:01:11.029244Z",
     "iopub.status.busy": "2025-03-19T22:01:11.028953Z",
     "iopub.status.idle": "2025-03-19T22:01:13.133342Z",
     "shell.execute_reply": "2025-03-19T22:01:13.132432Z",
     "shell.execute_reply.started": "2025-03-19T22:01:11.029223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/test.csv')\n",
    "\n",
    "# Generate file paths correctly\n",
    "train_df['file_path'] = train_df.apply(\n",
    "    lambda row: f\"/kaggle/input/bttai-ajl-2025/train/train/{row['label']}/{row['md5hash']}.jpg\", axis=1\n",
    ")\n",
    "test_df['file_path'] = test_df['md5hash'].apply(\n",
    "    lambda x: f\"/kaggle/input/bttai-ajl-2025/test/test/{x}.jpg\"\n",
    ")\n",
    "\n",
    "# Remove invalid rows\n",
    "train_df = train_df[(train_df['fitzpatrick_scale'] > 0) & (train_df['label'].notna())]\n",
    "train_df = train_df[train_df['file_path'].apply(os.path.exists)]\n",
    "test_df = test_df[test_df['file_path'].apply(os.path.exists)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "\n",
    "This section demonstrates basic preprocessing techniques. To enhance data quality and model performance, consider incorporating more advanced preprocessing methods.\n",
    "\n",
    "For further guidance, feel free to take a look at the [Image Preprocessing tutorial](https://colab.research.google.com/drive/1-ItNcRMbZBE6BCwPT-wD8m3YmHqwHxme?usp=sharing)  available in the 'Resources' section of this Kaggle competition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T22:15:04.978968Z",
     "iopub.status.busy": "2025-03-19T22:15:04.978613Z",
     "iopub.status.idle": "2025-03-19T22:15:08.149113Z",
     "shell.execute_reply": "2025-03-19T22:15:08.148253Z",
     "shell.execute_reply.started": "2025-03-19T22:15:04.978939Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1760 validated image filenames.\n",
      "Found 441 validated image filenames.\n",
      "Found 1227 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['encoded_label'] = label_encoder.fit_transform(train_df['label'])\n",
    "\n",
    "\n",
    "# Splitting dataset into training and validation datasets\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['encoded_label'])\n",
    "\n",
    "\n",
    "\n",
    "# Define image data generators for training and testing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='file_path',\n",
    "    y_col='encoded_label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=128,\n",
    "    class_mode='raw'\n",
    ")\n",
    "\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='file_path',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=128,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    "    \n",
    ")\n",
    "\n",
    "# Compute Class Weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_df['encoded_label']),\n",
    "    y=train_df['encoded_label']\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='file_path',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T22:01:13.177332Z",
     "iopub.status.busy": "2025-03-19T22:01:13.177062Z",
     "iopub.status.idle": "2025-03-19T22:01:13.180679Z",
     "shell.execute_reply": "2025-03-19T22:01:13.179960Z",
     "shell.execute_reply.started": "2025-03-19T22:01:13.177302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T22:01:46.167284Z",
     "iopub.status.busy": "2025-03-19T22:01:46.166967Z",
     "iopub.status.idle": "2025-03-19T22:13:35.326077Z",
     "shell.execute_reply": "2025-03-19T22:13:35.325253Z",
     "shell.execute_reply.started": "2025-03-19T22:01:46.167259Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.0789 - loss: 3.2266\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.1968 - loss: 2.5984\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.2530 - loss: 2.2901\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.3239 - loss: 2.1718\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.3717 - loss: 1.9918\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.4081 - loss: 1.7626\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.4203 - loss: 1.6589\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.4377 - loss: 1.6243\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.4700 - loss: 1.4823\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5161 - loss: 1.3810\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.4952 - loss: 1.3822\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5474 - loss: 1.2849\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5566 - loss: 1.2412\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5714 - loss: 1.1702\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5737 - loss: 1.1275\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5572 - loss: 1.1497\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5947 - loss: 1.0701\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.6165 - loss: 1.0513\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.6254 - loss: 0.9873\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.6265 - loss: 0.9546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7aeb9c755810>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),  # Reduces feature maps to a vector\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.25),  # Dropout to prevent overfitting\n",
    "    Dense(21, activation='softmax')  # Output layer (21 classes)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator, epochs=20,class_weight=class_weights_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T22:15:26.912168Z",
     "iopub.status.busy": "2025-03-19T22:15:26.911763Z",
     "iopub.status.idle": "2025-03-19T22:15:48.741312Z",
     "shell.execute_reply": "2025-03-19T22:15:48.740656Z",
     "shell.execute_reply.started": "2025-03-19T22:15:26.912125Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step  \n",
      "F1 Score: 0.7524760398093262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 321ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate predictions\n",
    "y_pred = np.argmax(model.predict(val_generator), axis=1)  # Convert probabilities to class indices\n",
    "y_true = val_df['encoded_label'].values  # Get actual labels from validation dataset\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')  # Use 'weighted' for imbalanced data\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "\n",
    "# SUBMISSION.CSV\n",
    "y_pred = np.argmax(model.predict(test_generator), axis = 1)\n",
    "test_df['label'] = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Save submission\n",
    "test_df[['md5hash', 'label']].to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10898385,
     "sourceId": 90489,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
