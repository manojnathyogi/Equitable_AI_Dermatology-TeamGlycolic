{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":90489,"databundleVersionId":10898385,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Import Necessary Libraries","metadata":{}},{"cell_type":"code","source":"# Import Necessary Libraries\nimport pandas as pd\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.applications import ResNet101\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.applications import ConvNeXtBase\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T01:15:40.839415Z","iopub.execute_input":"2025-03-23T01:15:40.839741Z","iopub.status.idle":"2025-03-23T01:15:41.147248Z","shell.execute_reply.started":"2025-03-23T01:15:40.839715Z","shell.execute_reply":"2025-03-23T01:15:41.146529Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## 2. Load Data + Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Load Data\ntrain_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/train.csv')\ntest_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/test.csv')\nprint(train_df.shape[0])\n\n# Generate file paths correctly\ntrain_df['file_path'] = train_df.apply(\n    lambda row: f\"/kaggle/input/bttai-ajl-2025/train/train/{row['label']}/{row['md5hash']}.jpg\", axis=1\n)\ntest_df['file_path'] = test_df['md5hash'].apply(\n    lambda x: f\"/kaggle/input/bttai-ajl-2025/test/test/{x}.jpg\"\n)\n\n# Data Preprocessing\n\n# Remove invalid rows\ntrain_df = train_df[(train_df['fitzpatrick_scale'] > 0) & (train_df['label'].notna())]\nprint(train_df.shape[0])\n\ntrain_df = train_df[train_df['file_path'].apply(os.path.exists)]\nprint(train_df.shape[0])\n\ntest_df = test_df[test_df['file_path'].apply(os.path.exists)]\nprint(test_df.shape[0])\nprint()\n\n\n# Encode the labels\nlabel_encoder = LabelEncoder()\ntrain_df['encoded_label'] = label_encoder.fit_transform(train_df['label'])\n\n\n# Splitting dataset into training and validation datasets\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['encoded_label'])\n\n# Define image data generators for training and testing\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    brightness_range=[0.9, 1.1],\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col='file_path',\n    y_col='encoded_label',\n    target_size=(224, 224),\n    batch_size=512,\n    class_mode='raw',\n    shuffle = True\n)\n\n\nval_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\nval_generator = val_datagen.flow_from_dataframe(\n    val_df,\n    x_col='file_path',\n    y_col='encoded_label',\n    target_size=(224, 224),\n    batch_size=512,\n    class_mode='raw',\n    shuffle=False\n    \n)\n\n\ntest_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\ntest_generator = test_datagen.flow_from_dataframe(\n    test_df,\n    x_col='file_path',\n    target_size=(224, 224),\n    batch_size= 512,\n    class_mode=None,\n    shuffle=False\n    \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T00:31:41.102636Z","iopub.execute_input":"2025-03-23T00:31:41.103096Z","iopub.status.idle":"2025-03-23T00:31:48.261446Z","shell.execute_reply.started":"2025-03-23T00:31:41.103073Z","shell.execute_reply":"2025-03-23T00:31:48.260573Z"}},"outputs":[{"name":"stdout","text":"2860\n2752\n2752\n1227\n\nFound 2201 validated image filenames.\nFound 551 validated image filenames.\nFound 1227 validated image filenames.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Common Model Parameters\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(train_df['encoded_label']),\n    y=train_df['encoded_label']\n)\nclass_weights_dict = dict(enumerate(class_weights))\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Initialize the ReduceLROnPlateau callback\nlr_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                 factor=0.5,  # Factor to reduce the learning rate\n                                 patience=3,  # Number of epochs to wait before reducing\n                                 min_lr=1e-6)  # Minimum learning rate","metadata":{"execution":{"iopub.status.busy":"2025-03-23T00:31:48.262919Z","iopub.execute_input":"2025-03-23T00:31:48.263179Z","iopub.status.idle":"2025-03-23T00:31:48.270296Z","shell.execute_reply.started":"2025-03-23T00:31:48.263157Z","shell.execute_reply":"2025-03-23T00:31:48.269537Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 4. Model Training","metadata":{}},{"cell_type":"code","source":"# Load ConvNeXtTiny with pre-trained weights\nbase_model = ConvNeXtBase(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False  # Freeze base model\n\n\n# Build the model\nmodel = models.Sequential([\n    base_model,  # Base model (ConvNeXtTiny)\n    layers.GlobalAveragePooling2D(),  # Pooling layer to reduce spatial dimensions\n    layers.BatchNormalization(),  # Batch normalization to stabilize training\n    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.0005)),  # First dense layer with more units\n    layers.Dropout(0.4),  # Increased dropout rate to prevent overfitting\n    layers.BatchNormalization(),  # Another batch normalization layer\n    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.0005)),  # Second dense layer\n    layers.Dropout(0.4),  # Dropout layer for regularization\n    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.0005)),  # Third dense layer\n    layers.Dropout(0.3),  # Dropout layer\n    layers.Dense(21, activation='softmax')  # Output layer with 21 classes (adjust accordingly)\n])\n\n# Compile the model\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(train_generator, epochs=30, validation_data=val_generator, callbacks=[lr_reduction])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T01:53:16.089917Z","iopub.execute_input":"2025-03-23T01:53:16.090266Z","iopub.status.idle":"2025-03-23T02:19:36.450219Z","shell.execute_reply.started":"2025-03-23T01:53:16.090237Z","shell.execute_reply":"2025-03-23T02:19:36.449288Z"},"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 8s/step - accuracy: 0.0567 - loss: 4.4915 - val_accuracy: 0.1815 - val_loss: 3.4528 - learning_rate: 0.0010\nEpoch 2/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.1713 - loss: 3.4934 - val_accuracy: 0.2795 - val_loss: 3.1992 - learning_rate: 0.0010\nEpoch 3/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.2574 - loss: 3.1648 - val_accuracy: 0.3031 - val_loss: 3.0556 - learning_rate: 0.0010\nEpoch 4/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.2867 - loss: 3.0152 - val_accuracy: 0.3249 - val_loss: 2.9915 - learning_rate: 0.0010\nEpoch 5/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.3570 - loss: 2.8068 - val_accuracy: 0.3412 - val_loss: 2.9416 - learning_rate: 0.0010\nEpoch 6/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.3651 - loss: 2.7304 - val_accuracy: 0.3575 - val_loss: 2.8826 - learning_rate: 0.0010\nEpoch 7/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.3933 - loss: 2.6724 - val_accuracy: 0.3721 - val_loss: 2.8065 - learning_rate: 0.0010\nEpoch 8/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.4272 - loss: 2.5228 - val_accuracy: 0.3920 - val_loss: 2.7273 - learning_rate: 0.0010\nEpoch 9/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.4170 - loss: 2.4756 - val_accuracy: 0.4029 - val_loss: 2.6626 - learning_rate: 0.0010\nEpoch 10/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.4458 - loss: 2.3957 - val_accuracy: 0.4174 - val_loss: 2.6146 - learning_rate: 0.0010\nEpoch 11/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.4610 - loss: 2.3261 - val_accuracy: 0.4265 - val_loss: 2.5764 - learning_rate: 0.0010\nEpoch 12/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.4916 - loss: 2.2596 - val_accuracy: 0.4574 - val_loss: 2.5341 - learning_rate: 0.0010\nEpoch 13/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5085 - loss: 2.1914 - val_accuracy: 0.4737 - val_loss: 2.4860 - learning_rate: 0.0010\nEpoch 14/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.4948 - loss: 2.1818 - val_accuracy: 0.4809 - val_loss: 2.4475 - learning_rate: 0.0010\nEpoch 15/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5426 - loss: 2.0603 - val_accuracy: 0.4918 - val_loss: 2.4098 - learning_rate: 0.0010\nEpoch 16/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5492 - loss: 2.0460 - val_accuracy: 0.4936 - val_loss: 2.3715 - learning_rate: 0.0010\nEpoch 17/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5556 - loss: 2.0036 - val_accuracy: 0.5191 - val_loss: 2.3437 - learning_rate: 0.0010\nEpoch 18/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5677 - loss: 1.9359 - val_accuracy: 0.5281 - val_loss: 2.3142 - learning_rate: 0.0010\nEpoch 19/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.6030 - loss: 1.8344 - val_accuracy: 0.5336 - val_loss: 2.2761 - learning_rate: 0.0010\nEpoch 20/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5934 - loss: 1.8454 - val_accuracy: 0.5336 - val_loss: 2.2370 - learning_rate: 0.0010\nEpoch 21/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5930 - loss: 1.8177 - val_accuracy: 0.5390 - val_loss: 2.1988 - learning_rate: 0.0010\nEpoch 22/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.6130 - loss: 1.7832 - val_accuracy: 0.5554 - val_loss: 2.1665 - learning_rate: 0.0010\nEpoch 23/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.6288 - loss: 1.7134 - val_accuracy: 0.5481 - val_loss: 2.1433 - learning_rate: 0.0010\nEpoch 24/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.6541 - loss: 1.6951 - val_accuracy: 0.5481 - val_loss: 2.1317 - learning_rate: 0.0010\nEpoch 25/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.6735 - loss: 1.5894 - val_accuracy: 0.5499 - val_loss: 2.1004 - learning_rate: 0.0010\nEpoch 26/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.6812 - loss: 1.5954 - val_accuracy: 0.5662 - val_loss: 2.0757 - learning_rate: 0.0010\nEpoch 27/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.6801 - loss: 1.5386 - val_accuracy: 0.5717 - val_loss: 2.0636 - learning_rate: 0.0010\nEpoch 28/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 4s/step - accuracy: 0.6913 - loss: 1.5297 - val_accuracy: 0.5662 - val_loss: 2.0624 - learning_rate: 0.0010\nEpoch 29/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.6998 - loss: 1.4887 - val_accuracy: 0.5554 - val_loss: 2.0599 - learning_rate: 0.0010\nEpoch 30/30\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.6991 - loss: 1.4748 - val_accuracy: 0.5608 - val_loss: 2.0540 - learning_rate: 0.0010\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7cc9361e8d90>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# Generate predictions\ny_prob = model.predict(val_generator)\ny_pred = np.argmax(y_prob, axis=1)\ny_true = val_df['encoded_label'].values\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\nf1 = f1_score(y_true, y_pred, average='weighted')\nprint(\"ConvNeXtTiny F1 Score:\", f1)","metadata":{"execution":{"iopub.status.busy":"2025-03-23T02:19:42.711376Z","iopub.execute_input":"2025-03-23T02:19:42.711695Z","iopub.status.idle":"2025-03-23T02:19:57.393798Z","shell.execute_reply.started":"2025-03-23T02:19:42.711668Z","shell.execute_reply":"2025-03-23T02:19:57.392961Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5s/step\n              precision    recall  f1-score   support\n\n           0       0.32      0.23      0.27        26\n           1       0.67      0.72      0.69        47\n           2       0.35      0.29      0.32        24\n           3       0.53      0.77      0.63        64\n           4       0.33      0.25      0.29         8\n           5       0.39      0.64      0.48        11\n           6       0.62      0.48      0.54        21\n           7       0.44      0.36      0.40        11\n           8       0.55      0.21      0.31        28\n           9       0.67      0.50      0.57        12\n          10       0.76      0.77      0.76        44\n          11       0.46      0.57      0.51        21\n          12       0.55      0.52      0.54        21\n          13       0.21      0.20      0.21        15\n          14       0.65      0.50      0.57        34\n          15       0.60      0.72      0.65        25\n          16       0.76      0.67      0.71        24\n          17       0.48      0.67      0.56        15\n          18       0.50      0.33      0.40         9\n          19       0.64      0.60      0.62        75\n          20       0.43      0.56      0.49        16\n\n    accuracy                           0.56       551\n   macro avg       0.52      0.50      0.50       551\nweighted avg       0.56      0.56      0.55       551\n\nConvNeXtTiny F1 Score: 0.5515171355792732\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# SUBMISSION.CSV\ny_pred = np.argmax(model.predict(test_generator), axis = 1)\ntest_df['label'] = label_encoder.inverse_transform(y_pred)\n\n# Save submission\ntest_df[['md5hash', 'label']].to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T02:20:01.883540Z","iopub.execute_input":"2025-03-23T02:20:01.883874Z","iopub.status.idle":"2025-03-23T02:20:21.736828Z","shell.execute_reply.started":"2025-03-23T02:20:01.883844Z","shell.execute_reply":"2025-03-23T02:20:21.736161Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4s/step\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}