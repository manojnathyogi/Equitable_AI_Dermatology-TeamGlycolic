{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":90489,"databundleVersionId":10898385,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Import Necessary Libraries","metadata":{}},{"cell_type":"code","source":"# Import Necessary Libraries\nimport pandas as pd\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.applications import ResNet101\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.applications import ConvNeXtBase\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T01:15:40.839415Z","iopub.execute_input":"2025-03-23T01:15:40.839741Z","iopub.status.idle":"2025-03-23T01:15:41.147248Z","shell.execute_reply.started":"2025-03-23T01:15:40.839715Z","shell.execute_reply":"2025-03-23T01:15:41.146529Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## 2. Load Data + Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Load Data\ntrain_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/train.csv')\ntest_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/test.csv')\nprint(train_df.shape[0])\n\n# Generate file paths correctly\ntrain_df['file_path'] = train_df.apply(\n    lambda row: f\"/kaggle/input/bttai-ajl-2025/train/train/{row['label']}/{row['md5hash']}.jpg\", axis=1\n)\ntest_df['file_path'] = test_df['md5hash'].apply(\n    lambda x: f\"/kaggle/input/bttai-ajl-2025/test/test/{x}.jpg\"\n)\n\n# Data Preprocessing\n\n# Remove invalid rows\ntrain_df = train_df[(train_df['fitzpatrick_scale'] > 0) & (train_df['label'].notna())]\nprint(train_df.shape[0])\n\ntrain_df = train_df[train_df['file_path'].apply(os.path.exists)]\nprint(train_df.shape[0])\n\ntest_df = test_df[test_df['file_path'].apply(os.path.exists)]\nprint(test_df.shape[0])\nprint()\n\n\n# Encode the labels\nlabel_encoder = LabelEncoder()\ntrain_df['encoded_label'] = label_encoder.fit_transform(train_df['label'])\n\n\n# Splitting dataset into training and validation datasets\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['encoded_label'])\n\n# Define image data generators for training and testing\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    brightness_range=[0.9, 1.1],\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col='file_path',\n    y_col='encoded_label',\n    target_size=(224, 224),\n    batch_size=512,\n    class_mode='raw',\n    shuffle = True\n)\n\n\nval_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\nval_generator = val_datagen.flow_from_dataframe(\n    val_df,\n    x_col='file_path',\n    y_col='encoded_label',\n    target_size=(224, 224),\n    batch_size=512,\n    class_mode='raw',\n    shuffle=False\n    \n)\n\n\ntest_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\ntest_generator = test_datagen.flow_from_dataframe(\n    test_df,\n    x_col='file_path',\n    target_size=(224, 224),\n    batch_size= 512,\n    class_mode=None,\n    shuffle=False\n    \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T00:31:41.102636Z","iopub.execute_input":"2025-03-23T00:31:41.103096Z","iopub.status.idle":"2025-03-23T00:31:48.261446Z","shell.execute_reply.started":"2025-03-23T00:31:41.103073Z","shell.execute_reply":"2025-03-23T00:31:48.260573Z"}},"outputs":[{"name":"stdout","text":"2860\n2752\n2752\n1227\n\nFound 2201 validated image filenames.\nFound 551 validated image filenames.\nFound 1227 validated image filenames.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Common Model Parameters\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(train_df['encoded_label']),\n    y=train_df['encoded_label']\n)\nclass_weights_dict = dict(enumerate(class_weights))\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Initialize the ReduceLROnPlateau callback\nlr_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                 factor=0.5,  # Factor to reduce the learning rate\n                                 patience=3,  # Number of epochs to wait before reducing\n                                 min_lr=1e-6)  # Minimum learning rate","metadata":{"execution":{"iopub.status.busy":"2025-03-23T00:31:48.262919Z","iopub.execute_input":"2025-03-23T00:31:48.263179Z","iopub.status.idle":"2025-03-23T00:31:48.270296Z","shell.execute_reply.started":"2025-03-23T00:31:48.263157Z","shell.execute_reply":"2025-03-23T00:31:48.269537Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 4. Model Training","metadata":{}},{"cell_type":"code","source":"# Load ConvNeXtTiny with pre-trained weights\nbase_model = ConvNeXtBase(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False  # Freeze base model\n\n\n# Build the model\nmodel = models.Sequential([\n    base_model,  # Base model (ConvNeXtTiny)\n    layers.GlobalAveragePooling2D(),  # Pooling layer to reduce spatial dimensions\n    layers.BatchNormalization(),  # Batch normalization to stabilize training\n    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.0005)),  # First dense layer with more units\n    layers.Dropout(0.4),  # Increased dropout rate to prevent overfitting\n    layers.BatchNormalization(),  # Another batch normalization layer\n    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.0005)),  # Second dense layer\n    layers.Dropout(0.4),  # Dropout layer for regularization\n    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.0005)),  # Third dense layer\n    layers.Dropout(0.3),  # Dropout layer\n    layers.Dense(21, activation='softmax')  # Output layer with 21 classes (adjust accordingly)\n])\n\n# Compile the model\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(train_generator, epochs=20, validation_data=val_generator, callbacks=[lr_reduction])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T01:21:38.608768Z","iopub.execute_input":"2025-03-23T01:21:38.609066Z","iopub.status.idle":"2025-03-23T01:40:03.561473Z","shell.execute_reply.started":"2025-03-23T01:21:38.609043Z","shell.execute_reply":"2025-03-23T01:40:03.560656Z"},"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_base_notop.h5\n\u001b[1m350926856/350926856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nEpoch 1/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 14s/step - accuracy: 0.0621 - loss: 4.2286 - val_accuracy: 0.2033 - val_loss: 3.4399 - learning_rate: 0.0010\nEpoch 2/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.2156 - loss: 3.3747 - val_accuracy: 0.2722 - val_loss: 3.2084 - learning_rate: 0.0010\nEpoch 3/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.2841 - loss: 3.1589 - val_accuracy: 0.3013 - val_loss: 3.0965 - learning_rate: 0.0010\nEpoch 4/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.3206 - loss: 2.9238 - val_accuracy: 0.3394 - val_loss: 3.0449 - learning_rate: 0.0010\nEpoch 5/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.3382 - loss: 2.8204 - val_accuracy: 0.3575 - val_loss: 2.9785 - learning_rate: 0.0010\nEpoch 6/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.3766 - loss: 2.6938 - val_accuracy: 0.3557 - val_loss: 2.9034 - learning_rate: 0.0010\nEpoch 7/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.4053 - loss: 2.6166 - val_accuracy: 0.3811 - val_loss: 2.8177 - learning_rate: 0.0010\nEpoch 8/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.4170 - loss: 2.5253 - val_accuracy: 0.4011 - val_loss: 2.7462 - learning_rate: 0.0010\nEpoch 9/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.4283 - loss: 2.4550 - val_accuracy: 0.4247 - val_loss: 2.6824 - learning_rate: 0.0010\nEpoch 10/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.4726 - loss: 2.3620 - val_accuracy: 0.4519 - val_loss: 2.6338 - learning_rate: 0.0010\nEpoch 11/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.4583 - loss: 2.3523 - val_accuracy: 0.4555 - val_loss: 2.5956 - learning_rate: 0.0010\nEpoch 12/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.4885 - loss: 2.2602 - val_accuracy: 0.4628 - val_loss: 2.5561 - learning_rate: 0.0010\nEpoch 13/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5127 - loss: 2.1949 - val_accuracy: 0.4791 - val_loss: 2.5086 - learning_rate: 0.0010\nEpoch 14/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5179 - loss: 2.1288 - val_accuracy: 0.5009 - val_loss: 2.4577 - learning_rate: 0.0010\nEpoch 15/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5323 - loss: 2.0983 - val_accuracy: 0.5136 - val_loss: 2.4117 - learning_rate: 0.0010\nEpoch 16/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5567 - loss: 2.0374 - val_accuracy: 0.5336 - val_loss: 2.3843 - learning_rate: 0.0010\nEpoch 17/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5825 - loss: 1.9605 - val_accuracy: 0.5354 - val_loss: 2.3467 - learning_rate: 0.0010\nEpoch 18/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5757 - loss: 1.9411 - val_accuracy: 0.5245 - val_loss: 2.3172 - learning_rate: 0.0010\nEpoch 19/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5887 - loss: 1.8959 - val_accuracy: 0.5318 - val_loss: 2.2903 - learning_rate: 0.0010\nEpoch 20/20\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4s/step - accuracy: 0.5776 - loss: 1.8724 - val_accuracy: 0.5390 - val_loss: 2.2698 - learning_rate: 0.0010\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7cc976b40250>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Generate predictions\ny_prob = model.predict(val_generator)\ny_pred = np.argmax(y_prob, axis=1)\ny_true = val_df['encoded_label'].values\n\n# Print classification report\nprint(classification_report(y_true, y_pred))\n\nf1 = f1_score(y_true, y_pred, average='weighted')\nprint(\"ConvNeXtTiny F1 Score:\", f1)","metadata":{"execution":{"iopub.status.busy":"2025-03-23T01:40:23.147059Z","iopub.execute_input":"2025-03-23T01:40:23.147412Z","iopub.status.idle":"2025-03-23T01:40:38.823686Z","shell.execute_reply.started":"2025-03-23T01:40:23.147378Z","shell.execute_reply":"2025-03-23T01:40:38.822748Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5s/step\n              precision    recall  f1-score   support\n\n           0       0.28      0.19      0.23        26\n           1       0.60      0.74      0.67        47\n           2       0.28      0.21      0.24        24\n           3       0.48      0.75      0.58        64\n           4       0.38      0.38      0.38         8\n           5       0.42      0.45      0.43        11\n           6       0.65      0.52      0.58        21\n           7       0.57      0.36      0.44        11\n           8       0.42      0.46      0.44        28\n           9       0.86      0.50      0.63        12\n          10       0.65      0.73      0.69        44\n          11       0.75      0.57      0.65        21\n          12       0.62      0.48      0.54        21\n          13       0.14      0.07      0.09        15\n          14       0.59      0.50      0.54        34\n          15       0.57      0.64      0.60        25\n          16       0.69      0.75      0.72        24\n          17       0.50      0.53      0.52        15\n          18       0.33      0.22      0.27         9\n          19       0.66      0.47      0.55        75\n          20       0.39      0.69      0.50        16\n\n    accuracy                           0.54       551\n   macro avg       0.52      0.49      0.49       551\nweighted avg       0.54      0.54      0.53       551\n\nConvNeXtTiny F1 Score: 0.5289250127377977\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# SUBMISSION.CSV\ny_pred = np.argmax(model.predict(test_generator), axis = 1)\ntest_df['label'] = label_encoder.inverse_transform(y_pred)\n\n# Save submission\ntest_df[['md5hash', 'label']].to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T01:41:52.033786Z","iopub.execute_input":"2025-03-23T01:41:52.034134Z","iopub.status.idle":"2025-03-23T01:42:26.420983Z","shell.execute_reply.started":"2025-03-23T01:41:52.034080Z","shell.execute_reply":"2025-03-23T01:42:26.420321Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8s/step\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}