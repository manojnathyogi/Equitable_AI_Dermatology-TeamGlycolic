{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90489,"databundleVersionId":10898385,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Import Necessary Libraries","metadata":{}},{"cell_type":"code","source":"# Import Necessary Libraries\nimport pandas as pd\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.applications import ResNet101\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T18:36:40.459826Z","iopub.execute_input":"2025-03-22T18:36:40.460200Z","iopub.status.idle":"2025-03-22T18:36:40.465368Z","shell.execute_reply.started":"2025-03-22T18:36:40.460172Z","shell.execute_reply":"2025-03-22T18:36:40.464391Z"}},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"## 2. Load Data + Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Load Data\ntrain_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/train.csv')\ntest_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/test.csv')\nprint(train_df.shape[0])\n\n# Generate file paths correctly\ntrain_df['file_path'] = train_df.apply(\n    lambda row: f\"/kaggle/input/bttai-ajl-2025/train/train/{row['label']}/{row['md5hash']}.jpg\", axis=1\n)\ntest_df['file_path'] = test_df['md5hash'].apply(\n    lambda x: f\"/kaggle/input/bttai-ajl-2025/test/test/{x}.jpg\"\n)\n\n# Data Preprocessing\n\n# Remove invalid rows\ntrain_df = train_df[(train_df['fitzpatrick_scale'] > 0) & (train_df['label'].notna())]\nprint(train_df.shape[0])\n\ntrain_df = train_df[train_df['file_path'].apply(os.path.exists)]\nprint(train_df.shape[0])\n\ntest_df = test_df[test_df['file_path'].apply(os.path.exists)]\nprint(test_df.shape[0])\nprint()\n\n\n# Encode the labels\nlabel_encoder = LabelEncoder()\ntrain_df['encoded_label'] = label_encoder.fit_transform(train_df['label'])\n\n\n# Splitting dataset into training and validation datasets\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['encoded_label'])\n\n# Define image data generators for training and testing\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    brightness_range=[0.9, 1.1],\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col='file_path',\n    y_col='encoded_label',\n    target_size=(224, 224),\n    batch_size=512,\n    class_mode='raw',\n    shuffle = True\n)\n\n\nval_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\nval_generator = val_datagen.flow_from_dataframe(\n    val_df,\n    x_col='file_path',\n    y_col='encoded_label',\n    target_size=(224, 224),\n    batch_size=512,\n    class_mode='raw',\n    shuffle=False\n    \n)\n\n\ntest_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\ntest_generator = test_datagen.flow_from_dataframe(\n    test_df,\n    x_col='file_path',\n    target_size=(224, 224),\n    batch_size= 512,\n    class_mode=None,\n    shuffle=False\n    \n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T18:38:34.438842Z","iopub.execute_input":"2025-03-22T18:38:34.439211Z","iopub.status.idle":"2025-03-22T18:38:38.835628Z","shell.execute_reply.started":"2025-03-22T18:38:34.439186Z","shell.execute_reply":"2025-03-22T18:38:38.834854Z"}},"outputs":[{"name":"stdout","text":"2860\n2752\n2752\n1227\n\nFound 2201 validated image filenames.\nFound 551 validated image filenames.\nFound 1227 validated image filenames.\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# Common Model Parameters\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(train_df['encoded_label']),\n    y=train_df['encoded_label']\n)\nclass_weights_dict = dict(enumerate(class_weights))\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Initialize the ReduceLROnPlateau callback\nlr_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                 factor=0.5,  # Factor to reduce the learning rate\n                                 patience=3,  # Number of epochs to wait before reducing\n                                 min_lr=1e-6)  # Minimum learning rate","metadata":{"execution":{"iopub.status.busy":"2025-03-22T18:38:44.622424Z","iopub.execute_input":"2025-03-22T18:38:44.622732Z","iopub.status.idle":"2025-03-22T18:38:44.629449Z","shell.execute_reply.started":"2025-03-22T18:38:44.622707Z","shell.execute_reply":"2025-03-22T18:38:44.628588Z"},"trusted":true},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"## 4. Model Training","metadata":{}},{"cell_type":"code","source":"base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False\nfor layer in base_model.layers[:230]:  \n    layer.trainable = False  \n\n\n\nefficientnetb0 = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.0005)),\n    layers.Dropout(0.25),\n    layers.Dense(21, activation='softmax')\n])\n\nefficientnetb0.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nefficientnetb0.fit(train_generator, epochs=30, validation_data=val_generator, class_weight = class_weights_dict callbacks=[lr_reduction])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate predictions\n# y_prob_res = ResNet101.predict(val_generator)\ny_prob_eff = efficientnetb0.predict(val_generator)\n# y_prob_combined = (0.6 * y_prob_res) + (0.4 * y_prob_eff)\n\n\n# y_pred_res = np.argmax(y_prob_res, axis=1) \ny_pred_eff = np.argmax(y_prob_eff, axis=1)\n# y_pred_combined = np.argmax(y_prob_combined, axis=1)\n\n\ny_true = val_df['encoded_label'].values \n\n# Calculate F1 Score\n# f1 = f1_score(y_true, y_pred_res, average='weighted')\n# print(\"ResNet 101 F1 Score:\", f1)\n\nf1 = f1_score(y_true, y_pred_eff, average='weighted')\nprint(\"Efficient Net b0 F1 Score:\", f1)\n\n# f1 = f1_score(y_true, y_pred_combined, average='weighted')\n# print(\"Combined F1 Sccore\", f1)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-22T19:43:21.093682Z","iopub.execute_input":"2025-03-22T19:43:21.094072Z","iopub.status.idle":"2025-03-22T19:43:36.647758Z","shell.execute_reply.started":"2025-03-22T19:43:21.094036Z","shell.execute_reply":"2025-03-22T19:43:36.647081Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5s/step\nEfficient Net b0 F1 Score: 0.4473521202175346\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# SUBMISSION.CSV\ny_pred = np.argmax(efficientnetb0.predict(test_generator), axis = 1)\ntest_df['label'] = label_encoder.inverse_transform(y_pred)\n\n# Save submission\ntest_df[['md5hash', 'label']].to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T19:04:11.425845Z","iopub.execute_input":"2025-03-22T19:04:11.426192Z","iopub.status.idle":"2025-03-22T19:04:45.703714Z","shell.execute_reply.started":"2025-03-22T19:04:11.426166Z","shell.execute_reply":"2025-03-22T19:04:45.703058Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9s/step \n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}