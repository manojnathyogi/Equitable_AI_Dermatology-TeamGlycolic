{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90489,"databundleVersionId":10898385,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import Necessary Libraries\nimport pandas as pd\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras import metrics\nfrom tensorflow.keras.applications import ResNet101\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.applications import ConvNeXtBase\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Data\ntrain_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/train.csv')\ntest_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/test.csv')\nprint(train_df.shape[0])\n\n# Generate file paths correctly\ntrain_df['file_path'] = train_df.apply(\n    lambda row: f\"/kaggle/input/bttai-ajl-2025/train/train/{row['label']}/{row['md5hash']}.jpg\", axis=1\n)\ntest_df['file_path'] = test_df['md5hash'].apply(\n    lambda x: f\"/kaggle/input/bttai-ajl-2025/test/test/{x}.jpg\"\n)\n\n# Data Preprocessing\n\n# Remove invalid rows\ntrain_df = train_df[(train_df['fitzpatrick_scale'] > 0) & (train_df['label'].notna())]\nprint(train_df.shape[0])\n\ntrain_df = train_df[train_df['file_path'].apply(os.path.exists)]\nprint(train_df.shape[0])\n\ntest_df = test_df[test_df['file_path'].apply(os.path.exists)]\nprint(test_df.shape[0])\nprint()\n\n\n# Encode the labels\nlabel_encoder = LabelEncoder()\ntrain_df['encoded_label'] = label_encoder.fit_transform(train_df['label'])\n\n\n# Splitting dataset into training and validation datasets\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['encoded_label'])\n\n# Define image data generators for training and testing\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    brightness_range=[0.9, 1.1],\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col='file_path',\n    y_col='encoded_label',\n    target_size=(224, 224),\n    batch_size=512,\n    class_mode='raw',\n    shuffle = True\n)\n\n\nval_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\nval_generator = val_datagen.flow_from_dataframe(\n    val_df,\n    x_col='file_path',\n    y_col='encoded_label',\n    target_size=(224, 224),\n    batch_size=512,\n    class_mode='raw',\n    shuffle=False\n    \n)\n\n\ntest_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input)\ntest_generator = test_datagen.flow_from_dataframe(\n    test_df,\n    x_col='file_path',\n    target_size=(224, 224),\n    batch_size= 512,\n    class_mode=None,\n    shuffle=False\n    \n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Common Model Parameters\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(train_df['encoded_label']),\n    y=train_df['encoded_label']\n)\nclass_weights_dict = dict(enumerate(class_weights))\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Initialize the ReduceLROnPlateau callback\nlr_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                 factor=0.5,  # Factor to reduce the learning rate\n                                 patience=3,  # Number of epochs to wait before reducing\n                                 min_lr=1e-6)  # Minimum learning rate\n\ncheckpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True, mode='max')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load ConvNeXtTiny with pre-trained weights\nbase_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False  # Freeze base model\n\n\n# Build the model\nmodel_eff = models.Sequential([\n    base_model,  # Base model (ConvNeXtTiny)\n    layers.GlobalAveragePooling2D(),  # Pooling layer to reduce spatial dimensions\n    layers.BatchNormalization(),  # Batch normalization to stabilize training\n    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.0005)),  # First dense layer with more units\n    layers.Dropout(0.4),  # Increased dropout rate to prevent overfitting\n    layers.BatchNormalization(),  # Another batch normalization layer\n    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.0005)),  # Second dense layer\n    layers.Dropout(0.4),  # Dropout layer for regularization\n    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.0005)),  # Third dense layer\n    layers.Dropout(0.3),  # Dropout layer\n    layers.Dense(21, activation='softmax')  # Output layer with 21 classes (adjust accordingly)\n])\n\n# Compile the model\nmodel_eff.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel_eff.fit(train_generator, epochs=40, validation_data=val_generator, callbacks=[lr_reduction, checkpoint])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load ConvNeXtTiny with pre-trained weights\nbase_model = ConvNeXtBase(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False  # Freeze base model\n\n\n# Build the model\nmodel_conv = models.Sequential([\n    base_model,  # Base model (ConvNeXtTiny)\n    layers.GlobalAveragePooling2D(),  # Pooling layer to reduce spatial dimensions\n    layers.BatchNormalization(),  # Batch normalization to stabilize training\n    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.0005)),  # First dense layer with more units\n    layers.Dropout(0.4),  # Increased dropout rate to prevent overfitting\n    layers.BatchNormalization(),  # Another batch normalization layer\n    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.0005)),  # Second dense layer\n    layers.Dropout(0.4),  # Dropout layer for regularization\n    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.0005)),  # Third dense layer\n    layers.Dropout(0.3),  # Dropout layer\n    layers.Dense(21, activation='softmax')  # Output layer with 21 classes (adjust accordingly)\n])\n\n# Compile the model\nmodel_conv.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel_conv.fit(train_generator, epochs=40, validation_data=val_generator, callbacks=[lr_reduction, checkpoint])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate predictions (probabilities)\ny_prob_conv = model_conv.predict(val_generator)\ny_prob_eff = model_eff.predict(val_generator)\ny_true = val_df['encoded_label'].values\n\n# Average the probabilities from both models\ny_prob_avg = (y_prob_conv + y_prob_eff) / 2\n\n# Convert averaged probabilities to predicted class labels\ny_pred_avg = np.argmax(y_prob_avg, axis=1)\n\n# Calculate the F1 Score for the averaged predictions\nf1_avg = f1_score(y_true, y_pred_avg, average='weighted')\nprint(\"Average F1 Score:\", f1_avg)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SUBMISSION.CSV\n\n# Generate predictions\ny_prob_conv = model_conv.predict(test_generator)  # Probabilities from ConvNet\ny_prob_eff = model_eff.predict(test_generator)  # Probabilities from EfficientNet\n\n# Average the probabilities\ny_prob= (y_pred_conv + y_pred_eff) / 2\n\n# Get the predicted class by taking the argmax\ny_pred = np.argmax(y_prob, axis=1)\n\n# Save submission\ntest_df['label'] = label_encoder.inverse_transform(y_pred)\ntest_df[['md5hash', 'label']].to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}