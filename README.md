# Equitable AI for Dermatology, AJL Kaggle Competition


### **üë• Team Members**

| Name | GitHub Handle | Contribution | <br />
| Bode Chiu | @BootyChu | Model Improvement |<br />
| Erica Xue | @ericaxuee | Model Improvement |<br />
| Manoj Yogi | @manojnathyogi | Data Visualization and Model  | <br />
| Natalie Kao | @nataliekao03 | Model Improvement |<br />
| Smila Gala | @Smila3 | Initial EDA and updating Discord README | <br />
| Sneha Nangunoori | @snehanangunoori | Model Development and FineTunning | <br />
| Precious Onah | | Model Improvement |<br />

---

## **üéØ Project Highlights**

**Example:**

* Built a \[insert model type\] using \[techniques used\] to predict more than 16 different skin conditions in different skin types
* Achieved an F1 score of \[insert score\] and a ranking of \[insert ranking out of participating teams\] on the final Kaggle Leaderboard
* Used \[explainability tool\] to interpret model decisions
* Implemented \[data preprocessing method\] to optimize results within compute constraints

üîó [Equitable AI for Dermatology | Kaggle Competition Page](https://www.kaggle.com/competitions/bttai-ajl-2025/overview)

## **üë©üèΩ‚Äçüíª Setup & Execution**

**How to run the Notebooks:**

* Clone the repository by pasting "git clone https://github.com/manojnathyogi/Equitable_AI_Dermatology-TeamGlycolic" in the terminal of your preferred IDE
* How to install dependencies
* How to set up the environment
* How to access the dataset(s)
* How to run the notebook or scripts

---

## **üèóÔ∏è Project Overview**

- Train a model to classify 16 different skin conditions using the provided dataset.
- Achieve high accuracy using the weighted F1 score as the evaluation metric.
- - Highlight fairness and inclusivity in the AI model.
- Use fairness and explainability tools, visualizations, or storytelling to center the "excluded" in the work

---

## **üìä Data Exploration**

**Describe:**

* The dataset(s) used (i.e., the data provided in Kaggle \+ any additional sources)
* Data exploration and preprocessing approaches
* Challenges and assumptions when working with the dataset(s)

**Potential visualizations to include:**

* Plots, charts, heatmaps, feature visualizations, sample dataset images

---

## **üß† Model Development**

**Describe (as applicable):**

* Model(s) used (e.g., CNN with transfer learning, regression models)
* Feature selection and Hyperparameter tuning strategies
* Training setup (e.g., % of data for training/validation, evaluation metric, baseline performance)

---

## **üìà Results & Key Findings**

**Describe (as applicable):**

* Performance metrics (e.g., Kaggle Leaderboard score, F1-score)
* How your model performed overall
* How your model performed across different skin tones (AJL)
* Insights from evaluating model fairness (AJL)

**Potential visualizations to include:**

* Confusion matrix, precision-recall curve, feature importance plot, prediction distribution, outputs from fairness or explainability tools

---

## **üñºÔ∏è Impact Narrative**

**Answer the relevant questions below based on your competition:**

**AJL challenge:**

As Dr. Randi mentioned in her challenge overview, ‚ÄúThrough poetry, art, and storytelling, you can reach others who might not know enough to understand what‚Äôs happening with the machine learning model or data visualizations, but might still be heavily impacted by this kind of work.‚Äù
As you answer the questions below, consider using not only text, but also illustrations, annotated visualizations, poetry, or other creative techniques to make your work accessible to a wider audience.
Check out [this guide](https://drive.google.com/file/d/1kYKaVNR\_l7Abx2kebs3AdDi6TlPviC3q/view) from the Algorithmic Justice League for inspiration!

1. What steps did you take to address [model fairness](https://haas.berkeley.edu/wp-content/uploads/What-is-fairness_-EGAL2.pdf)? (e.g., leveraging data augmentation techniques to account for training dataset imbalances; using a validation set to assess model performance across different skin tones)
2. What broader impact could your work have?

---

## **üöÄ Next Steps & Future Improvements**

**Address the following:**

* What are some of the limitations of your model?<br />
  We had some difficulties with the model overfitting the data and inconsistencies with our results after running the model several times
* What would you do differently with more time/resources? <br />
  With more time and resources we could have researched better the reason behind the inconsistencies of our results and work around those
* What additional datasets or techniques would you explore? <br />
  We would explore different techniques related to ensemble models and other image-oriented EDA

---

## **üìÑ References & Additional Resources**

1. [Create custom Data Generator for TensorFlow](https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3)
2. [Sample Keras Image Classification Models](https://keras.io/examples/vision/image_classification_from_scratch/)
3. [Ensemble Model Tutorials](https://pytorch.org/tutorials/intermediate/ensembling.html)
4. [Fine-Tuning Resources part 1](http://restack.io/)
5. [Fine-Tuning Resources part 2](https://huggingface.co/docs/transformers/en/training)

---

