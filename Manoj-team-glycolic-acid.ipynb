{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":90489,"databundleVersionId":10898385,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetV2B0, ResNet50, ConvNeXtTiny\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nimport warnings\n\n# Mixed precision for faster training and better generalization\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\n\nwarnings.filterwarnings('ignore')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-18T22:14:36.559052Z","iopub.execute_input":"2025-03-18T22:14:36.559438Z","iopub.status.idle":"2025-03-18T22:14:50.455521Z","shell.execute_reply.started":"2025-03-18T22:14:36.559391Z","shell.execute_reply":"2025-03-18T22:14:50.454459Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ============ Load Data ============\ntrain_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/train.csv')\ntest_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/test.csv')\n\n# Generate file paths\ntrain_df['file_path'] = train_df.apply(\n    lambda row: f\"/kaggle/input/bttai-ajl-2025/train/train/{row['label']}/{row['md5hash']}.jpg\", axis=1\n)\ntest_df['file_path'] = test_df['md5hash'].apply(\n    lambda x: f\"/kaggle/input/bttai-ajl-2025/test/test/{x}.jpg\"\n)\n\n# Remove invalid rows\ntrain_df = train_df[(train_df['fitzpatrick_scale'] > 0) & (train_df['label'].notna())]\ntrain_df = train_df[train_df['file_path'].apply(os.path.exists)]\ntest_df = test_df[test_df['file_path'].apply(os.path.exists)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T22:14:58.852233Z","iopub.execute_input":"2025-03-18T22:14:58.852947Z","iopub.status.idle":"2025-03-18T22:15:04.173171Z","shell.execute_reply.started":"2025-03-18T22:14:58.852907Z","shell.execute_reply":"2025-03-18T22:15:04.172131Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ============ Encode Labels ============\nlabel_encoder = LabelEncoder()\ntrain_df['encoded_label'] = label_encoder.fit_transform(train_df['label'])\n\nnum_classes = len(label_encoder.classes_)\n\n# ============ Compute Class Weights ============\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(train_df['encoded_label']),\n    y=train_df['encoded_label']\n)\nclass_weights_dict = dict(enumerate(class_weights))\n\n# ============ Learning Rate Scheduler ============\ndef cosine_decay_with_warmup(epoch, lr):\n    warmup_epochs = 3\n    if epoch < warmup_epochs:\n        return lr * (epoch + 1) / warmup_epochs\n    else:\n        return 1e-4 * 0.5 * (1 + np.cos(np.pi * (epoch - warmup_epochs) / (50 - warmup_epochs)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T22:15:06.649379Z","iopub.execute_input":"2025-03-18T22:15:06.649740Z","iopub.status.idle":"2025-03-18T22:15:06.661907Z","shell.execute_reply.started":"2025-03-18T22:15:06.649711Z","shell.execute_reply":"2025-03-18T22:15:06.661001Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ============ Mixup and Cutmix ============\ndef mixup(batch_images, batch_labels, alpha=0.4):\n    lam = np.random.beta(alpha, alpha)\n    index = np.random.permutation(batch_images.shape[0])\n    mixed_images = lam * batch_images + (1 - lam) * batch_images[index]\n    mixed_labels = lam * batch_labels + (1 - lam) * batch_labels[index]\n    return mixed_images, mixed_labels\n\ndef cutmix(batch_images, batch_labels, alpha=0.4):\n    lam = np.random.beta(alpha, alpha)\n    h, w = batch_images.shape[1:3]\n    r_x = np.random.uniform(0, w)\n    r_y = np.random.uniform(0, h)\n    r_w = w * np.sqrt(1 - lam)\n    r_h = h * np.sqrt(1 - lam)\n\n    x1 = int(np.clip(r_x - r_w / 2, 0, w))\n    y1 = int(np.clip(r_y - r_h / 2, 0, h))\n    x2 = int(np.clip(r_x + r_w / 2, 0, w))\n    y2 = int(np.clip(r_y + r_h / 2, 0, h))\n\n    index = np.random.permutation(batch_images.shape[0])\n    batch_images[:, y1:y2, x1:x2, :] = batch_images[index, y1:y2, x1:x2, :]\n    batch_labels = lam * batch_labels + (1 - lam) * batch_labels[index]\n\n    return batch_images, batch_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T22:15:09.415646Z","iopub.execute_input":"2025-03-18T22:15:09.415961Z","iopub.status.idle":"2025-03-18T22:15:09.422880Z","shell.execute_reply.started":"2025-03-18T22:15:09.415939Z","shell.execute_reply":"2025-03-18T22:15:09.422066Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\n# ============ Data Augmentation ============\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    brightness_range=[0.8, 1.2],\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\ntrain_generator = datagen.flow_from_dataframe(\n    train_df,\n    x_col='file_path',\n    y_col='encoded_label',\n    target_size=(512, 512),  # ✅ Increased size for better details\n    batch_size=16,           # ✅ Smaller batch size for stability\n    class_mode='raw'\n)\n\ntest_datagen = ImageDataGenerator()\ntest_generator = test_datagen.flow_from_dataframe(\n    test_df,\n    x_col='file_path',\n    target_size=(512, 512),\n    batch_size=16,\n    class_mode=None,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T22:15:11.310012Z","iopub.execute_input":"2025-03-18T22:15:11.310372Z","iopub.status.idle":"2025-03-18T22:15:13.107358Z","shell.execute_reply.started":"2025-03-18T22:15:11.310339Z","shell.execute_reply":"2025-03-18T22:15:13.106345Z"}},"outputs":[{"name":"stdout","text":"Found 2752 validated image filenames.\nFound 1227 validated image filenames.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============ Build Model ============\ndef build_model(base_model):\n    base_model.trainable = False\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dropout(0.5)(x)\n    output = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=output)\n    return model\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T22:15:13.943075Z","iopub.execute_input":"2025-03-18T22:15:13.943440Z","iopub.status.idle":"2025-03-18T22:15:13.948320Z","shell.execute_reply.started":"2025-03-18T22:15:13.943409Z","shell.execute_reply":"2025-03-18T22:15:13.947352Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# EfficientNetV2B0\nmodel1 = build_model(EfficientNetV2B0(include_top=False, weights='imagenet', input_shape=(512, 512, 3)))\nmodel1.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel1.fit(train_generator, epochs=30, class_weight=class_weights_dict)\nprint(\"complete\")\n\n# ResNet50\nmodel2 = build_model(ResNet50(include_top=False, weights='imagenet', input_shape=(512, 512, 3)))\nmodel2.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel2.fit(train_generator, epochs=30, class_weight=class_weights_dict)\nprint(\"complete\")\n\n# ConvNeXtTiny\nmodel3 = build_model(ConvNeXtTiny(include_top=False, weights='imagenet', input_shape=(512, 512, 3)))\nmodel3.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel3.fit(train_generator, epochs=30, class_weight=class_weights_dict)\nprint(\"complete\")\n\n# ============ Model Averaging ============\npred1 = model1.predict(test_generator)\npred2 = model2.predict(test_generator)\npred3 = model3.predict(test_generator)\n\nfinal_predictions = (0.4 * pred1) + (0.3 * pred2) + (0.3 * pred3)\ntest_df['label'] = label_encoder.inverse_transform(np.argmax(final_predictions, axis=1))\n\n# ============ Create Submission ============\nsubmission = test_df[['md5hash', 'label']]\nsubmission.to_csv('/kaggle/working/sample_submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T22:15:16.590959Z","iopub.execute_input":"2025-03-18T22:15:16.591253Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n\u001b[1m24274472/24274472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nEpoch 1/30\n\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 1s/step - accuracy: 0.0552 - loss: 3.1580\nEpoch 2/30\n\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 1s/step - accuracy: 0.0919 - loss: 2.9705\nEpoch 3/30\n\u001b[1m113/172\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:12\u001b[0m 1s/step - accuracy: 0.1027 - loss: 2.9312","output_type":"stream"}],"execution_count":null}]}